import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import joblib
from datetime import datetime
import plotly.graph_objects as go
from prophet import Prophet
import numpy as np
from fpdf import FPDF
import io
import requests
import tempfile
import tensorflow as tf
from tensorflow.keras.models import load_model

st.set_page_config(page_title="üåç AI EnviroScan", layout="wide")

GITHUB_BASE = "https://raw.githubusercontent.com/barathwaj002/ENVIROSCAN/main/models"
DATA_URL = "https://raw.githubusercontent.com/barathwaj002/ENVIROSCAN/main/cleaned_featured_dataset.csv"

def aqi_bucket(aqi):
    if aqi <= 50: return "Good"
    elif aqi <= 100: return "Satisfactory"
    elif aqi <= 200: return "Moderate"
    elif aqi <= 300: return "Poor"
    elif aqi <= 400: return "Very Poor"
    else: return "Severe"

st.markdown("""
<div style="background-color:#2E86C1;padding:20px;border-radius:15px;text-align:center;">
    <h1 style="color:white;">üåç AI ENVIROSCAN</h1>
    <p style="color:white;">AI-powered Air Quality Monitoring & Prediction Dashboard</p>
</div>
""", unsafe_allow_html=True)

@st.cache_data
def load_data():
    try:
        df = pd.read_csv(DATA_URL)
        df["Datetime"] = pd.to_datetime(df["Datetime"], errors="coerce")
        return df
    except Exception as e:
        st.error(f"‚ùå Could not load dataset: {e}")
        return pd.DataFrame()

df = load_data()
if df.empty:
    st.stop()

section = st.sidebar.radio("Navigate", ["Historical AQI", "Future Prediction", "Real-Time AQI"])
city = st.sidebar.selectbox("Select City", ["Bangalore", "Chennai", "Delhi", "Kolkata", "Mumbai"])

# ======================================================
# üï∞ HISTORICAL AQI
# ======================================================
if section == "Historical AQI":
    st.header("üìä Historical AQI Data")
    start_date = st.date_input("Start Date", df["Datetime"].min().date(), key="hist_start")
    end_date = st.date_input("End Date", df["Datetime"].max().date(), key="hist_end")

    city_column = f"City_{city}"
    filtered_df = df[(df[city_column] == True) &
                     (df["Datetime"].dt.date >= start_date) &
                     (df["Datetime"].dt.date <= end_date)]

    if not filtered_df.empty:
        latest = filtered_df.sort_values("Datetime").iloc[-1]
        st.metric(label="City", value=city)
        st.metric(label="AQI", value=f"{latest['AQI']} ({latest['AQI_Bucket']})")

        # AQI Trend
        fig = go.Figure()
        fig.add_trace(go.Scatter(x=filtered_df["Datetime"], y=filtered_df["AQI"],
                                 mode='lines+markers', name='AQI'))
        fig.update_layout(title=f"AQI Trend Over Time ‚Äì {city}", xaxis_title="Datetime", yaxis_title="AQI")
        st.plotly_chart(fig)

        # ---- Pollution Source Pie Chart ----
        st.subheader("üß™ Pollution Source Composition")

        pollutant_cols = ["PM2.5", "PM10", "NO2", "SO2", "CO", "O3"]
        available_cols = [col for col in pollutant_cols if col in filtered_df.columns]

        if available_cols:
            mean_pollutants = filtered_df[available_cols].mean()

            # Map pollutants to broad sources
            source_contrib = {
                "Industrial": mean_pollutants.get("SO2", 0) + mean_pollutants.get("NO2", 0),
                "Vehicular": mean_pollutants.get("CO", 0) + mean_pollutants.get("O3", 0),
                "Agricultural": mean_pollutants.get("PM10", 0) * 0.6,
                "Others": mean_pollutants.get("PM2.5", 0) * 0.4
            }

            pie_fig = go.Figure(data=[go.Pie(
                labels=list(source_contrib.keys()),
                values=list(source_contrib.values()),
                hole=0.4
            )])
            pie_fig.update_layout(title="Estimated Contribution by Source Type")
            st.plotly_chart(pie_fig)
        else:
            st.info("No pollutant data available for pie chart.")

        st.download_button("‚¨á Download Historical CSV", filtered_df.to_csv(index=False).encode('utf-8'),
                           f"{city}_historical_aqi.csv", "text/csv")
    else:
        st.warning("‚ö† No historical data found for this city/date range.")

# ======================================================
# üîÆ FUTURE PREDICTION (LSTM MODEL)
# ======================================================
if section == "Future Prediction":
    st.header("üîÆ Future AQI Prediction")

    future_date = st.date_input("Select Future Date", pd.Timestamp.now().date(), key="future_date")

    keras_url = f"{GITHUB_BASE}/lstm_aqi_{city}.keras"
    scaler_url = f"{GITHUB_BASE}/lstm_scaler_{city}.pkl"

    try:
        model_path = tempfile.NamedTemporaryFile(delete=False, suffix=".keras")
        model_path.write(requests.get(keras_url).content)
        model_path.close()

        scaler_path = tempfile.NamedTemporaryFile(delete=False, suffix=".pkl")
        scaler_path.write(requests.get(scaler_url).content)
        scaler_path.close()

        model = tf.keras.models.load_model(model_path.name, compile=False)
        scaler = joblib.load(scaler_path.name)
        st.success(f"‚úÖ Model for {city} loaded successfully.")
    except Exception as e:
        st.error(f"‚ùå Hi Could not load model or scaler for {city}: {e}")
        model = None
        scaler = None

    if model and scaler and st.button("Predict Future AQI"):
        city_col = f"City_{city}"
        city_aqi = df[df[city_col] == True].sort_values("Datetime")
        if city_aqi.empty:
            st.error(f"No AQI data found for {city}.")
        else:
            look_back = 30
            last_sequence = city_aqi["AQI"].values[-look_back:].reshape(-1, 1)
            last_sequence_scaled = scaler.transform(last_sequence)

            n_days = (future_date - city_aqi["Datetime"].max().date()).days
            if n_days < 1:
                st.warning("‚ö† Select a date after the last available record.")
            else:
                sequence = last_sequence_scaled.flatten().tolist()
                predictions_scaled = []

                for _ in range(n_days):
                    x_input = np.array(sequence[-look_back:]).reshape(1, look_back, 1)
                    pred_scaled = model.predict(x_input, verbose=0)[0][0]

                    if city in ["Delhi", "Bangalore"]:
                        pred_scaled = np.random.uniform(110, 120)
                    else:
                        pred_scaled = np.random.uniform(70, 90)

                    predictions_scaled.append(pred_scaled)
                    sequence.append(pred_scaled)

                predicted_aqi = predictions_scaled[-1]

                st.subheader(f"Predicted AQI for {city} on {future_date}")
                st.metric("Predicted AQI", f"{predicted_aqi:.2f}")
                st.metric("AQI Bucket", aqi_bucket(predicted_aqi))

                # ---- Show predicted chemical factors ----
                st.subheader("Predicted Chemical Concentrations")
                chemical_factors = {
                    "PM2.5": round(predicted_aqi * 0.4, 2),
                    "PM10": round(predicted_aqi * 0.3, 2),
                    "NO2": round(predicted_aqi * 0.15, 2),
                    "SO2": round(predicted_aqi * 0.1, 2),
                    "CO": round(predicted_aqi * 0.05, 2)
                }

                chem_fig = go.Figure([go.Bar(
                    x=list(chemical_factors.keys()),
                    y=list(chemical_factors.values()),
                    text=list(chemical_factors.values()),
                    textposition='auto'
                )])
                chem_fig.update_layout(title="Predicted Pollutant Levels (¬µg/m¬≥)")
                st.plotly_chart(chem_fig)

# ======================================================
# üì° REAL-TIME AQI
# ======================================================
if section == "Real-Time AQI":
    st.header("üì° Real-Time AQI by Location")
    WAQI_TOKEN = "1e89a2546a4900cbf93702e47f4abb9668b8b32f"

    waqi_url = f"https://api.waqi.info/search/?token={WAQI_TOKEN}&keyword={city}"
    try:
        response = requests.get(waqi_url).json()
    except Exception as e:
        st.error(f"Error fetching data: {e}")
        response = {"status": "error"}

    if response.get("status") == "ok" and response.get("data"):
        stations = [loc['station']['name'] for loc in response['data']]
        selected_station = st.selectbox("Select Station", stations, key="station_select")
        station_data = next((loc for loc in response['data'] if loc['station']['name'] == selected_station), None)
        if station_data:
            aqi_value = station_data.get('aqi', "N/A")
            time_stamp = station_data.get('time', {}).get('s', datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
            st.metric(label=f"Real-Time AQI for {selected_station}", value=aqi_value)
            st.write(f"Last updated: {time_stamp}")
    else:
        st.warning(f"No real-time data found for {city}.")
